{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a534af5-2e76-4bd5-bcf2-ac7b47cdfcc3",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec047ce5-27db-4a50-b406-60550eb93572",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from preprocessing import *\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from sklearn import metrics\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e76957a-6361-41b3-8a78-94bd151d51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORINGS = [\"roc_auc\", \"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "METRIC = \"roc_auc\"\n",
    "\n",
    "def grid_table(grid, params):\n",
    "    tabla = pd.DataFrame(grid.cv_results_)\n",
    "    tabla.sort_values(\"rank_test_\" + METRIC, inplace = True)\n",
    "    tabla.reset_index(inplace = True)\n",
    "    cols = [\"param_\" + x for x in params] + [\"mean_test_\" + x for x in SCORINGS]\n",
    "    return tabla[cols]\n",
    "\n",
    "def metrics_table(model, X, Y):\n",
    "    predicted = model.predict(X)\n",
    "    probabilities = model.decision_function(X)\n",
    "    roc_auc = metrics.roc_auc_score(Y, probabilities)\n",
    "    f1 = metrics.f1_score(Y, predicted)\n",
    "    acc = metrics.accuracy_score(Y, predicted)\n",
    "    rec = metrics.recall_score(Y, predicted)\n",
    "    prec = metrics.precision_score(Y, predicted)\n",
    "    return pd.DataFrame.from_dict({\n",
    "        \"AUC-ROC\": [roc_auc], \"Accuracy\": [acc], \"Precision\": [prec], \"Recall\": [rec], \"F1 Score\": [f1]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c9c7a-9e8b-49a0-8477-9e556af3ebd1",
   "metadata": {},
   "source": [
    "## SVM Lineal (Grado 1) y Polinómico (Grados 2 y 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d4835ed-0671-405f-9eb1-cff1738e5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_dataset()\n",
    "\n",
    "df_features = pd.read_csv(\"datasets/df_features.csv\", low_memory = False, index_col = \"id\")\n",
    "df_target = pd.read_csv(\"datasets/df_target.csv\", low_memory = False, index_col = \"id\")\n",
    "\n",
    "common(df_features, df_target)\n",
    "viento_trigonometrico(df_features)\n",
    "# El barrio tiene 49 valores distintos. Para no tener que hacer one hoy con 48 columnas nuevas, uso hashing trick/\n",
    "# En total quedan 47 features luego de esto\n",
    "df_features = hashing_trick(df_features, 24, \"barrio\")\n",
    "pipe = iterative_imputer()\n",
    "pipe = standarizer(pipe)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_features, df_target, test_size = 0.20, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f5efb4-ea25-4ab9-8fd8-d422bf8119cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La grid tarda muchísimo en terminar, si se desea se puede cargar de archivo y saltear el próximo bloque\n",
    "# de código, descomentando la siguiente línea. También se pueden saltear los próximos 3 bloques de código si\n",
    "# solo se desea ver el modelo final con los parámetros encontrados.\n",
    "# grid = load('SVM/polinomico_grid.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec6c38a-ace9-431c-b431-4ea6f31faf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8804586778572769"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_grid = pipe.fit_transform(X_train)\n",
    "\n",
    "grid = GridSearchCV(SVC(kernel = 'poly', random_state = 123, max_iter=100000),\n",
    "                    param_grid = {\n",
    "                        \"C\": [0.01, 1, 1000],\n",
    "                        \"coef0\": [1, 1000],\n",
    "                        \"degree\": [1, 2, 3],\n",
    "                        \"gamma\": [0.001, 0.01, 1]\n",
    "                    },\n",
    "                    verbose = 1, n_jobs = -1, cv = 3, scoring = SCORINGS, refit = METRIC)\n",
    "\n",
    "grid.fit(X_grid, Y_train.values.ravel())\n",
    "\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1bf69e5-5687-483a-9483-db202bc35bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM/polinomico_grid.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(grid, 'SVM/polinomico_grid.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69a5434d-988d-4d7b-a809-40e27d6933d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>param_coef0</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.880459</td>\n",
       "      <td>0.858544</td>\n",
       "      <td>0.790836</td>\n",
       "      <td>0.499836</td>\n",
       "      <td>0.612527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.876455</td>\n",
       "      <td>0.856150</td>\n",
       "      <td>0.787229</td>\n",
       "      <td>0.489134</td>\n",
       "      <td>0.603370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.875499</td>\n",
       "      <td>0.849774</td>\n",
       "      <td>0.772615</td>\n",
       "      <td>0.465491</td>\n",
       "      <td>0.580922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.875315</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>0.805392</td>\n",
       "      <td>0.402588</td>\n",
       "      <td>0.536818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872609</td>\n",
       "      <td>0.857347</td>\n",
       "      <td>0.779234</td>\n",
       "      <td>0.505515</td>\n",
       "      <td>0.613215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.871613</td>\n",
       "      <td>0.848174</td>\n",
       "      <td>0.756023</td>\n",
       "      <td>0.474391</td>\n",
       "      <td>0.582960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.871585</td>\n",
       "      <td>0.847343</td>\n",
       "      <td>0.764178</td>\n",
       "      <td>0.459430</td>\n",
       "      <td>0.573807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.870375</td>\n",
       "      <td>0.839538</td>\n",
       "      <td>0.804965</td>\n",
       "      <td>0.373103</td>\n",
       "      <td>0.509859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.868428</td>\n",
       "      <td>0.847014</td>\n",
       "      <td>0.737581</td>\n",
       "      <td>0.490718</td>\n",
       "      <td>0.589304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.867644</td>\n",
       "      <td>0.845426</td>\n",
       "      <td>0.744845</td>\n",
       "      <td>0.470023</td>\n",
       "      <td>0.576326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.867541</td>\n",
       "      <td>0.845340</td>\n",
       "      <td>0.745807</td>\n",
       "      <td>0.468221</td>\n",
       "      <td>0.575255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.867534</td>\n",
       "      <td>0.845340</td>\n",
       "      <td>0.746025</td>\n",
       "      <td>0.467948</td>\n",
       "      <td>0.575111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.867533</td>\n",
       "      <td>0.845365</td>\n",
       "      <td>0.746068</td>\n",
       "      <td>0.468058</td>\n",
       "      <td>0.575207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.867532</td>\n",
       "      <td>0.845401</td>\n",
       "      <td>0.746352</td>\n",
       "      <td>0.467948</td>\n",
       "      <td>0.575206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.866660</td>\n",
       "      <td>0.843887</td>\n",
       "      <td>0.755153</td>\n",
       "      <td>0.447145</td>\n",
       "      <td>0.561655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.866657</td>\n",
       "      <td>0.843826</td>\n",
       "      <td>0.754992</td>\n",
       "      <td>0.446926</td>\n",
       "      <td>0.561440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.866417</td>\n",
       "      <td>0.844534</td>\n",
       "      <td>0.718350</td>\n",
       "      <td>0.502403</td>\n",
       "      <td>0.591036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.862286</td>\n",
       "      <td>0.827495</td>\n",
       "      <td>0.822476</td>\n",
       "      <td>0.291854</td>\n",
       "      <td>0.430795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.862286</td>\n",
       "      <td>0.827507</td>\n",
       "      <td>0.822710</td>\n",
       "      <td>0.291799</td>\n",
       "      <td>0.430765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.861686</td>\n",
       "      <td>0.855014</td>\n",
       "      <td>0.747211</td>\n",
       "      <td>0.531888</td>\n",
       "      <td>0.621337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.860830</td>\n",
       "      <td>0.781336</td>\n",
       "      <td>0.860190</td>\n",
       "      <td>0.026865</td>\n",
       "      <td>0.052101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.777586</td>\n",
       "      <td>0.843956</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>0.014076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.860247</td>\n",
       "      <td>0.843581</td>\n",
       "      <td>0.718654</td>\n",
       "      <td>0.494649</td>\n",
       "      <td>0.585839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.860208</td>\n",
       "      <td>0.842274</td>\n",
       "      <td>0.720707</td>\n",
       "      <td>0.482474</td>\n",
       "      <td>0.577642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.859857</td>\n",
       "      <td>0.776414</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.859856</td>\n",
       "      <td>0.776414</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.858361</td>\n",
       "      <td>0.832454</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.568794</td>\n",
       "      <td>0.601358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857216</td>\n",
       "      <td>0.841725</td>\n",
       "      <td>0.716943</td>\n",
       "      <td>0.483346</td>\n",
       "      <td>0.577357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.855328</td>\n",
       "      <td>0.840564</td>\n",
       "      <td>0.704391</td>\n",
       "      <td>0.495522</td>\n",
       "      <td>0.581679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.845179</td>\n",
       "      <td>0.825308</td>\n",
       "      <td>0.606056</td>\n",
       "      <td>0.626349</td>\n",
       "      <td>0.615421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.844804</td>\n",
       "      <td>0.829339</td>\n",
       "      <td>0.640952</td>\n",
       "      <td>0.543191</td>\n",
       "      <td>0.587337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.841677</td>\n",
       "      <td>0.830512</td>\n",
       "      <td>0.657353</td>\n",
       "      <td>0.506225</td>\n",
       "      <td>0.571906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.758843</td>\n",
       "      <td>0.726005</td>\n",
       "      <td>0.424926</td>\n",
       "      <td>0.620237</td>\n",
       "      <td>0.503714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.647964</td>\n",
       "      <td>0.679358</td>\n",
       "      <td>0.341724</td>\n",
       "      <td>0.457737</td>\n",
       "      <td>0.390822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.635094</td>\n",
       "      <td>0.628814</td>\n",
       "      <td>0.312690</td>\n",
       "      <td>0.538991</td>\n",
       "      <td>0.395392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.630455</td>\n",
       "      <td>0.601710</td>\n",
       "      <td>0.314533</td>\n",
       "      <td>0.595824</td>\n",
       "      <td>0.409539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630410</td>\n",
       "      <td>0.654330</td>\n",
       "      <td>0.318381</td>\n",
       "      <td>0.479307</td>\n",
       "      <td>0.382440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624316</td>\n",
       "      <td>0.678319</td>\n",
       "      <td>0.332106</td>\n",
       "      <td>0.432620</td>\n",
       "      <td>0.375714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619222</td>\n",
       "      <td>0.658483</td>\n",
       "      <td>0.316875</td>\n",
       "      <td>0.455170</td>\n",
       "      <td>0.373579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.604844</td>\n",
       "      <td>0.574460</td>\n",
       "      <td>0.287278</td>\n",
       "      <td>0.574911</td>\n",
       "      <td>0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601660</td>\n",
       "      <td>0.625858</td>\n",
       "      <td>0.295249</td>\n",
       "      <td>0.481814</td>\n",
       "      <td>0.365847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601660</td>\n",
       "      <td>0.625858</td>\n",
       "      <td>0.295249</td>\n",
       "      <td>0.481814</td>\n",
       "      <td>0.365847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601660</td>\n",
       "      <td>0.625858</td>\n",
       "      <td>0.295249</td>\n",
       "      <td>0.481814</td>\n",
       "      <td>0.365847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.593796</td>\n",
       "      <td>0.629156</td>\n",
       "      <td>0.286430</td>\n",
       "      <td>0.442668</td>\n",
       "      <td>0.347531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.586334</td>\n",
       "      <td>0.580225</td>\n",
       "      <td>0.284437</td>\n",
       "      <td>0.525610</td>\n",
       "      <td>0.367375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564450</td>\n",
       "      <td>0.599487</td>\n",
       "      <td>0.268281</td>\n",
       "      <td>0.453367</td>\n",
       "      <td>0.336464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559805</td>\n",
       "      <td>0.571210</td>\n",
       "      <td>0.254728</td>\n",
       "      <td>0.467618</td>\n",
       "      <td>0.328230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.554930</td>\n",
       "      <td>0.552254</td>\n",
       "      <td>0.253637</td>\n",
       "      <td>0.511738</td>\n",
       "      <td>0.338434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.536880</td>\n",
       "      <td>0.571785</td>\n",
       "      <td>0.260122</td>\n",
       "      <td>0.429227</td>\n",
       "      <td>0.322046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.535500</td>\n",
       "      <td>0.562966</td>\n",
       "      <td>0.248794</td>\n",
       "      <td>0.460800</td>\n",
       "      <td>0.322952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529880</td>\n",
       "      <td>0.630512</td>\n",
       "      <td>0.254996</td>\n",
       "      <td>0.342360</td>\n",
       "      <td>0.291924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.515360</td>\n",
       "      <td>0.516441</td>\n",
       "      <td>0.236882</td>\n",
       "      <td>0.496612</td>\n",
       "      <td>0.319731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.488757</td>\n",
       "      <td>0.589325</td>\n",
       "      <td>0.225475</td>\n",
       "      <td>0.338100</td>\n",
       "      <td>0.268828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.470859</td>\n",
       "      <td>0.578112</td>\n",
       "      <td>0.221688</td>\n",
       "      <td>0.322872</td>\n",
       "      <td>0.262090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_degree param_coef0 param_gamma  mean_test_roc_auc  \\\n",
       "0        1            3           1        0.01           0.880459   \n",
       "1        1            2           1        0.01           0.876455   \n",
       "2        1            3           1       0.001           0.875499   \n",
       "3     0.01            3           1        0.01           0.875315   \n",
       "4     0.01            2           1           1           0.872609   \n",
       "5     0.01            2        1000        0.01           0.871613   \n",
       "6        1            2           1       0.001           0.871585   \n",
       "7     0.01            2           1        0.01           0.870375   \n",
       "8        1            2        1000       0.001           0.868428   \n",
       "9     0.01            2        1000       0.001           0.867644   \n",
       "10       1            1        1000        0.01           0.867541   \n",
       "11       1            1           1        0.01           0.867534   \n",
       "12    0.01            1           1           1           0.867533   \n",
       "13    0.01            1        1000           1           0.867532   \n",
       "14       1            1        1000       0.001           0.866660   \n",
       "15       1            1           1       0.001           0.866657   \n",
       "16    1000            2        1000       0.001           0.866417   \n",
       "17    0.01            1        1000        0.01           0.862286   \n",
       "18    0.01            1           1        0.01           0.862286   \n",
       "19    1000            2           1       0.001           0.861686   \n",
       "20    0.01            3           1       0.001           0.860830   \n",
       "21    0.01            2           1       0.001           0.860302   \n",
       "22    1000            1           1       0.001           0.860247   \n",
       "23       1            1        1000           1           0.860208   \n",
       "24    0.01            1        1000       0.001           0.859857   \n",
       "25    0.01            1           1       0.001           0.859856   \n",
       "26    1000            1        1000       0.001           0.858361   \n",
       "27       1            1           1           1           0.857216   \n",
       "28    0.01            3        1000       0.001           0.855328   \n",
       "29    1000            3           1       0.001           0.845179   \n",
       "30    1000            3        1000       0.001           0.844804   \n",
       "31       1            3        1000       0.001           0.841677   \n",
       "32    1000            1        1000        0.01           0.758843   \n",
       "33    1000            3           1        0.01           0.647964   \n",
       "34    1000            1           1           1           0.635094   \n",
       "35       1            3        1000        0.01           0.630455   \n",
       "36    1000            3           1           1           0.630410   \n",
       "37    0.01            3           1           1           0.624316   \n",
       "38       1            3           1           1           0.619222   \n",
       "39    0.01            3        1000        0.01           0.604844   \n",
       "40       1            3        1000           1           0.601660   \n",
       "41    0.01            3        1000           1           0.601660   \n",
       "42    1000            3        1000           1           0.601660   \n",
       "43    0.01            2        1000           1           0.593796   \n",
       "44    1000            2        1000        0.01           0.586334   \n",
       "45       1            2        1000           1           0.564450   \n",
       "46    1000            2        1000           1           0.559805   \n",
       "47       1            2        1000        0.01           0.554930   \n",
       "48    1000            1           1        0.01           0.536880   \n",
       "49    1000            1        1000           1           0.535500   \n",
       "50       1            2           1           1           0.529880   \n",
       "51    1000            3        1000        0.01           0.515360   \n",
       "52    1000            2           1           1           0.488757   \n",
       "53    1000            2           1        0.01           0.470859   \n",
       "\n",
       "    mean_test_accuracy  mean_test_precision  mean_test_recall  mean_test_f1  \n",
       "0             0.858544             0.790836          0.499836      0.612527  \n",
       "1             0.856150             0.787229          0.489134      0.603370  \n",
       "2             0.849774             0.772615          0.465491      0.580922  \n",
       "3             0.844595             0.805392          0.402588      0.536818  \n",
       "4             0.857347             0.779234          0.505515      0.613215  \n",
       "5             0.848174             0.756023          0.474391      0.582960  \n",
       "6             0.847343             0.764178          0.459430      0.573807  \n",
       "7             0.839538             0.804965          0.373103      0.509859  \n",
       "8             0.847014             0.737581          0.490718      0.589304  \n",
       "9             0.845426             0.744845          0.470023      0.576326  \n",
       "10            0.845340             0.745807          0.468221      0.575255  \n",
       "11            0.845340             0.746025          0.467948      0.575111  \n",
       "12            0.845365             0.746068          0.468058      0.575207  \n",
       "13            0.845401             0.746352          0.467948      0.575206  \n",
       "14            0.843887             0.755153          0.447145      0.561655  \n",
       "15            0.843826             0.754992          0.446926      0.561440  \n",
       "16            0.844534             0.718350          0.502403      0.591036  \n",
       "17            0.827495             0.822476          0.291854      0.430795  \n",
       "18            0.827507             0.822710          0.291799      0.430765  \n",
       "19            0.855014             0.747211          0.531888      0.621337  \n",
       "20            0.781336             0.860190          0.026865      0.052101  \n",
       "21            0.777586             0.843956          0.007098      0.014076  \n",
       "22            0.843581             0.718654          0.494649      0.585839  \n",
       "23            0.842274             0.720707          0.482474      0.577642  \n",
       "24            0.776414             0.933333          0.000546      0.001091  \n",
       "25            0.776414             0.933333          0.000546      0.001091  \n",
       "26            0.832454             0.655555          0.568794      0.601358  \n",
       "27            0.841725             0.716943          0.483346      0.577357  \n",
       "28            0.840564             0.704391          0.495522      0.581679  \n",
       "29            0.825308             0.606056          0.626349      0.615421  \n",
       "30            0.829339             0.640952          0.543191      0.587337  \n",
       "31            0.830512             0.657353          0.506225      0.571906  \n",
       "32            0.726005             0.424926          0.620237      0.503714  \n",
       "33            0.679358             0.341724          0.457737      0.390822  \n",
       "34            0.628814             0.312690          0.538991      0.395392  \n",
       "35            0.601710             0.314533          0.595824      0.409539  \n",
       "36            0.654330             0.318381          0.479307      0.382440  \n",
       "37            0.678319             0.332106          0.432620      0.375714  \n",
       "38            0.658483             0.316875          0.455170      0.373579  \n",
       "39            0.574460             0.287278          0.574911      0.381699  \n",
       "40            0.625858             0.295249          0.481814      0.365847  \n",
       "41            0.625858             0.295249          0.481814      0.365847  \n",
       "42            0.625858             0.295249          0.481814      0.365847  \n",
       "43            0.629156             0.286430          0.442668      0.347531  \n",
       "44            0.580225             0.284437          0.525610      0.367375  \n",
       "45            0.599487             0.268281          0.453367      0.336464  \n",
       "46            0.571210             0.254728          0.467618      0.328230  \n",
       "47            0.552254             0.253637          0.511738      0.338434  \n",
       "48            0.571785             0.260122          0.429227      0.322046  \n",
       "49            0.562966             0.248794          0.460800      0.322952  \n",
       "50            0.630512             0.254996          0.342360      0.291924  \n",
       "51            0.516441             0.236882          0.496612      0.319731  \n",
       "52            0.589325             0.225475          0.338100      0.268828  \n",
       "53            0.578112             0.221688          0.322872      0.262090  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_table(grid, [\"C\", \"degree\", \"coef0\", \"gamma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0a9855-727a-405e-ad23-b2d2218d508a",
   "metadata": {},
   "source": [
    "Podemos ver que para la gran mayoría de las combinaciones de parámetros, el modelo no convergió en las 100000 iteraciones (el error nos sugiere estandarizar los datos, pero ya se hizo).\n",
    "\n",
    "El mejor modelo resultó ser el de un polinomio de grado 3, con C = 1, coef0 = 1 y gamma = 0.01. Los primeros de la lista son todos de grado 3, lo cual tiene sentido al estar menos sesgados. Como el grid search utiliza cross validation, confiamos en que no overfittearon.\n",
    "\n",
    "Vamos a entrenar un modelo con esos parámetros y probarlo con el set de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "389db321-934a-4b6c-8750-d04ff031e44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.882422</td>\n",
       "      <td>0.857094</td>\n",
       "      <td>0.793818</td>\n",
       "      <td>0.491518</td>\n",
       "      <td>0.607119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUC-ROC  Accuracy  Precision    Recall  F1 Score\n",
       "0  0.882422  0.857094   0.793818  0.491518  0.607119"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps.append(['svc', SVC(kernel = 'poly', random_state = 123, max_iter=100000,\n",
    "                             C = 1, degree = 3, coef0 = 1, gamma = 0.01)])\n",
    "\n",
    "pipe.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "metrics_table(pipe, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b877e-3245-4ff5-ba84-3eee3a9f1bb1",
   "metadata": {},
   "source": [
    "Con los parámetros encontrados, el modelo dio un accuracy de alrededor de 85,7% y área bajo la curva ROC de 0.882."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97383ca-e5cd-4a99-b38a-8db27037af54",
   "metadata": {},
   "source": [
    "## SVM Radial (RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff61607-5db9-472b-a6bc-3f437ff00c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_dataset()\n",
    "\n",
    "df_features = pd.read_csv(\"datasets/df_features.csv\", low_memory = False, index_col = \"id\")\n",
    "df_target = pd.read_csv(\"datasets/df_target.csv\", low_memory = False, index_col = \"id\")\n",
    "\n",
    "common(df_features, df_target)\n",
    "viento_trigonometrico(df_features)\n",
    "# El barrio tiene 49 valores distintos. Para no tener que hacer one hoy con 48 columnas nuevas, uso hashing trick\n",
    "df_features = hashing_trick(df_features, 24, \"barrio\")\n",
    "pipe2 = iterative_imputer()\n",
    "pipe2 = standarizer(pipe2)\n",
    "\n",
    "# Son los mismos sets, tienen el mismo random state\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_features, df_target, test_size = 0.20, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "103f11f0-94cd-4af7-b8bf-751b7ff8200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La grid tarda muchísimo en terminar, si se desea se puede cargar de archivo y saltear el próximo bloque\n",
    "# de código, descomentando la siguiente línea. También se pueden saltear los próximos 3 bloques de código si\n",
    "# solo se desea ver el modelo final con los parámetros encontrados.\n",
    "# grid2 = load('SVM/radial_grid.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2e6efe5-eb91-4946-8370-72dfb32f974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8791220991523808"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_grid = pipe2.fit_transform(X_train)\n",
    "\n",
    "grid2 = GridSearchCV(SVC(kernel = 'rbf', random_state = 123, max_iter=100000),\n",
    "                    param_grid = {\n",
    "                        \"C\": [0.01, 1, 1000],\n",
    "                        \"gamma\": [0.001, 0.01, 1]\n",
    "                    },\n",
    "                    verbose = 1, n_jobs = -1, cv = 3, scoring = SCORINGS, refit = METRIC)\n",
    "\n",
    "grid2.fit(X_grid, Y_train.values.ravel())\n",
    "\n",
    "grid2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "297eaafe-68c9-4952-a070-377dfe51d420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM/radial_grid.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(grid2, 'SVM/radial_grid.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9edcf57a-cfd4-498b-834b-7da5c158ddb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.879122</td>\n",
       "      <td>0.857762</td>\n",
       "      <td>0.788735</td>\n",
       "      <td>0.497379</td>\n",
       "      <td>0.610049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.873783</td>\n",
       "      <td>0.848638</td>\n",
       "      <td>0.769968</td>\n",
       "      <td>0.461232</td>\n",
       "      <td>0.576850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.867683</td>\n",
       "      <td>0.857017</td>\n",
       "      <td>0.743791</td>\n",
       "      <td>0.551162</td>\n",
       "      <td>0.632968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.866850</td>\n",
       "      <td>0.826860</td>\n",
       "      <td>0.838492</td>\n",
       "      <td>0.279950</td>\n",
       "      <td>0.419734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.860568</td>\n",
       "      <td>0.777000</td>\n",
       "      <td>0.834213</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.007932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.780974</td>\n",
       "      <td>0.776548</td>\n",
       "      <td>0.646962</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.004787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.780150</td>\n",
       "      <td>0.776304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.779413</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>0.014631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.690681</td>\n",
       "      <td>0.720533</td>\n",
       "      <td>0.389446</td>\n",
       "      <td>0.430487</td>\n",
       "      <td>0.408606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_gamma  mean_test_roc_auc  mean_test_accuracy  \\\n",
       "0       1        0.01           0.879122            0.857762   \n",
       "1       1       0.001           0.873783            0.848638   \n",
       "2    1000       0.001           0.867683            0.857017   \n",
       "3    0.01        0.01           0.866850            0.826860   \n",
       "4    0.01       0.001           0.860568            0.777000   \n",
       "5       1           1           0.780974            0.776548   \n",
       "6    0.01           1           0.780150            0.776304   \n",
       "7    1000           1           0.779413            0.776316   \n",
       "8    1000        0.01           0.690681            0.720533   \n",
       "\n",
       "   mean_test_precision  mean_test_recall  mean_test_f1  \n",
       "0             0.788735          0.497379      0.610049  \n",
       "1             0.769968          0.461232      0.576850  \n",
       "2             0.743791          0.551162      0.632968  \n",
       "3             0.838492          0.279950      0.419734  \n",
       "4             0.834213          0.003986      0.007932  \n",
       "5             0.646962          0.002403      0.004787  \n",
       "6             0.000000          0.000000      0.000000  \n",
       "7             0.500000          0.007426      0.014631  \n",
       "8             0.389446          0.430487      0.408606  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_table(grid2, [\"C\", \"gamma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04d625-9e4c-4c32-9570-d59787172d22",
   "metadata": {},
   "source": [
    "Nuevamente, la mayoría de los modelos con cada combinación de los parámetros no logró converger antes de las iteraciones dadas. Casi todos los modelos dieron 77% de accuracy, lo cual es muy malo ya que probablemente hayan fiteado a decir siempre que \"no\" al estar desbalanceada la variable target. El que dio recall y precision en 0 overfitteo por completo (0 true positives, entonces 0 de recall y precision).\n",
    "\n",
    "Los primeros si dieron valores más aceptables, siendo el de mejor el que usa C=1 y gamma=0.01. Vamos a utilizar esos valores para entrenar un modelo con todo el set de entrenamietno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489c4b3a-1fd7-49e8-ac76-82de688fe5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880191</td>\n",
       "      <td>0.856263</td>\n",
       "      <td>0.793409</td>\n",
       "      <td>0.486951</td>\n",
       "      <td>0.603504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUC-ROC  Accuracy  Precision    Recall  F1 Score\n",
       "0  0.880191  0.856263   0.793409  0.486951  0.603504"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.steps.append(['svc', SVC(kernel = 'rbf', random_state = 123, max_iter=100000, C = 1, gamma = 0.01)])\n",
    "\n",
    "pipe2.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "metrics_table(pipe2, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ff338-87ce-48ae-82b3-148820b402cf",
   "metadata": {},
   "source": [
    "En este caso el modelo radial dio un 0.880 de área bajo curva ROC y accuracy del 85,6%, muy levemente por debajo del polinómico. El  recall sigue siendo malo, tiene muchos falsos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab86dcc-a00d-4178-b5fc-42ca6b1c65b2",
   "metadata": {},
   "source": [
    "## Con otro scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db81390e-f50f-4b71-9972-80e8db1614bc",
   "metadata": {},
   "source": [
    "Como en SVM es bastante importante el escalado de los valores de las features, para mantener las distancias parejas, vamos a probar otro preprocesamiento con un MinMaxScaler con los parámetros del primer modelo a ver si da mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b1fc72-1ce1-47b5-954f-ef012d90831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_dataset()\n",
    "\n",
    "df_features = pd.read_csv(\"datasets/df_features.csv\", low_memory = False, index_col = \"id\")\n",
    "df_target = pd.read_csv(\"datasets/df_target.csv\", low_memory = False, index_col = \"id\")\n",
    "\n",
    "common(df_features, df_target)\n",
    "viento_trigonometrico(df_features)\n",
    "\n",
    "df_features = hashing_trick(df_features, 24, \"barrio\")\n",
    "pipe3 = iterative_imputer()\n",
    "pipe3 = minmax(pipe3)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_features, df_target, test_size = 0.20, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2cb02e8-03b5-49b7-8d01-600306977a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.869172</td>\n",
       "      <td>0.842974</td>\n",
       "      <td>0.75976</td>\n",
       "      <td>0.440191</td>\n",
       "      <td>0.557422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUC-ROC  Accuracy  Precision    Recall  F1 Score\n",
       "0  0.869172  0.842974    0.75976  0.440191  0.557422"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe3.steps.append(['svc', SVC(kernel = 'poly', random_state = 123, max_iter=100000,\n",
    "                             C = 1, degree = 3, coef0 = 1, gamma = 0.01)])\n",
    "\n",
    "pipe3.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "metrics_table(pipe3, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf1984-02eb-4786-8f73-09ac09d1a104",
   "metadata": {},
   "source": [
    "Dio un poco peor que con el StandardScaler, asi que nos vamos a quedar con ese."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d3e45-7168-4f43-a2e4-04ce7662c6e7",
   "metadata": {},
   "source": [
    "## Predicción de nuevos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a7d86-aa42-4838-b31b-efc3ff283683",
   "metadata": {},
   "source": [
    "Como el modelo polinómico dio un poco mejor, vamos a utilizar este modelo para predecir sobre los nuevos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "550cdce6-c805-4347-b039-7e409a2f7cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llovieron_hamburguesas_al_dia_siguiente</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116706</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58831</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31981</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73456</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14471</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106482</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21057</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102055</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29092 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       llovieron_hamburguesas_al_dia_siguiente\n",
       "id                                            \n",
       "116706                                      no\n",
       "58831                                       no\n",
       "31981                                       no\n",
       "2533                                        no\n",
       "7270                                        si\n",
       "...                                        ...\n",
       "73456                                       no\n",
       "14471                                       no\n",
       "106482                                      no\n",
       "21057                                       no\n",
       "102055                                      no\n",
       "\n",
       "[29092 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_dataset()\n",
    "\n",
    "df_extra = pd.read_csv(\"datasets/df_extra.csv\", low_memory = False, index_col = \"id\")\n",
    "\n",
    "common(df_extra)\n",
    "viento_trigonometrico(df_extra)\n",
    "df_extra = hashing_trick(df_extra, 24, \"barrio\")\n",
    "\n",
    "# El imputer y standarizer ya estan en el pipe\n",
    "\n",
    "df_extra_predict = pd.DataFrame({\"id\": df_extra.index, \"llovieron_hamburguesas_al_dia_siguiente\": pipe.predict(df_extra)})\n",
    "df_extra_predict.set_index(\"id\", inplace = True)\n",
    "df_extra_predict.replace({\"llovieron_hamburguesas_al_dia_siguiente\": {0.0: \"no\", 1.0: \"si\"}}, inplace = True)\n",
    "df_extra_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd41adc3-b284-49c0-aa90-9ea3f5aa0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extra_predict.to_csv(\"predicciones/SVM.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a41260-5047-45bd-9d1f-b9eba20fd98b",
   "metadata": {},
   "source": [
    "## Predicciones en el holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f2055a-21ae-42c0-badc-d8736d5bdb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.885517</td>\n",
       "      <td>0.856842</td>\n",
       "      <td>0.796333</td>\n",
       "      <td>0.479684</td>\n",
       "      <td>0.59872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUC-ROC  Accuracy  Precision    Recall  F1 Score\n",
       "0  0.885517  0.856842   0.796333  0.479684   0.59872"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_dataset()\n",
    "\n",
    "X_holdout = pd.read_csv(\"datasets/df_features_holdout.csv\", low_memory = False, index_col = \"id\")\n",
    "Y_holdout = pd.read_csv(\"datasets/df_target_holdout.csv\", low_memory = False, index_col = \"id\")\n",
    "\n",
    "common(X_holdout, Y_holdout)\n",
    "viento_trigonometrico(X_holdout)\n",
    "X_holdout = hashing_trick(X_holdout, 24, \"barrio\")\n",
    "\n",
    "# El imputer y standarizer ya estan en el pipe\n",
    "\n",
    "metrics_table(pipe, X_holdout, Y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4713843f-bb49-40a4-87fd-049dfa695b5d",
   "metadata": {},
   "source": [
    "Dio resultados bastante buenos, mejores que en el set de validación en términos de AUC_ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20e426c-c2a2-46e9-a52b-241c69737b52",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb72f237-ede1-4115-a7cc-9851b06280f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(Y_holdout, pipe.predict(X_holdout))\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b88586-2bdd-4925-9f61-b9b2b7a25c27",
   "metadata": {},
   "source": [
    "### Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "855126a1-ff0a-4b24-9a68-0f48d7cc7370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "RocCurveDisplay.from_predictions(Y_holdout, pipe.decision_function(X_holdout), name = \"SVM Polinómico (d=3)\", ax = ax)\n",
    "ax.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea82983-b2a8-4879-8dec-54636d5d5ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
