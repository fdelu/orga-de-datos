{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a534af5-2e76-4bd5-bcf2-ac7b47cdfcc3",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec047ce5-27db-4a50-b406-60550eb93572",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from preprocessing import *\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e76957a-6361-41b3-8a78-94bd151d51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORINGS = [\"roc_auc\", \"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "METRIC = \"roc_auc\"\n",
    "\n",
    "def grid_table(grid, params):\n",
    "    tabla = pd.DataFrame(grid.cv_results_)\n",
    "    tabla.sort_values(\"rank_test_\" + METRIC, inplace = True)\n",
    "    tabla.reset_index(inplace = True)\n",
    "    cols = [\"param_\" + x for x in params] + [\"mean_test_\" + x for x in SCORINGS]\n",
    "    return tabla[cols]\n",
    "\n",
    "def metrics_table(model, X, Y):\n",
    "    predicted = model.predict(X)\n",
    "    probabilities = model.decision_function(X)\n",
    "    roc_auc = metrics.roc_auc_score(Y, probabilities)\n",
    "    f1 = metrics.f1_score(Y, predicted)\n",
    "    acc = metrics.accuracy_score(Y, predicted)\n",
    "    rec = metrics.recall_score(Y, predicted)\n",
    "    prec = metrics.precision_score(Y, predicted)\n",
    "    return pd.DataFrame.from_dict({\n",
    "        \"AUC-ROC\": [roc_auc], \"Accuracy\": [acc], \"Precision\": [prec], \"Recall\": [rec], \"F1 Score\": [f1]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c9c7a-9e8b-49a0-8477-9e556af3ebd1",
   "metadata": {},
   "source": [
    "## SVM Lineal (Grado 1) y Polinómico (Grados 2 y 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d4835ed-0671-405f-9eb1-cff1738e5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_dataset()\n",
    "\n",
    "df_features = pd.read_csv(\"datasets/df_features.csv\", low_memory = False, index_col = \"id\")\n",
    "df_target = pd.read_csv(\"datasets/df_target.csv\", low_memory = False, index_col = \"id\")\n",
    "\n",
    "common(df_features, df_target)\n",
    "viento_trigonometrico(df_features)\n",
    "# El barrio tiene 49 valores distintos. Para no tener que hacer one hoy con 48 columnas nuevas, uso hashing trick/\n",
    "# En total quedan 47 features luego de esto\n",
    "df_features = hashing_trick(df_features, 24, \"barrio\")\n",
    "pipe = iterative_imputer()\n",
    "pipe = standarizer(pipe)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_features, df_target, test_size = 0.20, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f5efb4-ea25-4ab9-8fd8-d422bf8119cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La grid tarda muchísimo en terminar, si se desea se puede cargar de archivo y saltear el próximo bloque\n",
    "# de código, descomentando la siguiente línea. También se pueden saltear los próximos 3 bloques de código si\n",
    "# solo se desea ver el modelo final con los parámetros encontrados.\n",
    "# grid = load('SVM/polinomico_grid.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec6c38a-ace9-431c-b431-4ea6f31faf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8804586778572769"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_grid = pipe.fit_transform(X_train)\n",
    "\n",
    "grid = GridSearchCV(SVC(kernel = 'poly', random_state = 123, max_iter=100000),\n",
    "                    param_grid = {\n",
    "                        \"C\": [0.01, 1, 1000],\n",
    "                        \"coef0\": [1, 1000],\n",
    "                        \"degree\": [1, 2, 3],\n",
    "                        \"gamma\": [0.001, 0.01, 1]\n",
    "                    },\n",
    "                    verbose = 1, n_jobs = -1, cv = 3, scoring = SCORINGS, refit = METRIC)\n",
    "\n",
    "grid.fit(X_grid, Y_train.values.ravel())\n",
    "\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1bf69e5-5687-483a-9483-db202bc35bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM/polinomico_grid.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(grid, 'SVM/polinomico_grid.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69a5434d-988d-4d7b-a809-40e27d6933d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>param_coef0</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.880459</td>\n",
       "      <td>0.858544</td>\n",
       "      <td>0.790836</td>\n",
       "      <td>0.499836</td>\n",
       "      <td>0.612527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.876455</td>\n",
       "      <td>0.856150</td>\n",
       "      <td>0.787229</td>\n",
       "      <td>0.489134</td>\n",
       "      <td>0.603370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.875499</td>\n",
       "      <td>0.849774</td>\n",
       "      <td>0.772615</td>\n",
       "      <td>0.465491</td>\n",
       "      <td>0.580922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.875315</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>0.805392</td>\n",
       "      <td>0.402588</td>\n",
       "      <td>0.536818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872609</td>\n",
       "      <td>0.857347</td>\n",
       "      <td>0.779234</td>\n",
       "      <td>0.505515</td>\n",
       "      <td>0.613215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.871613</td>\n",
       "      <td>0.848174</td>\n",
       "      <td>0.756023</td>\n",
       "      <td>0.474391</td>\n",
       "      <td>0.582960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.871585</td>\n",
       "      <td>0.847343</td>\n",
       "      <td>0.764178</td>\n",
       "      <td>0.459430</td>\n",
       "      <td>0.573807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.870375</td>\n",
       "      <td>0.839538</td>\n",
       "      <td>0.804965</td>\n",
       "      <td>0.373103</td>\n",
       "      <td>0.509859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.868428</td>\n",
       "      <td>0.847014</td>\n",
       "      <td>0.737581</td>\n",
       "      <td>0.490718</td>\n",
       "      <td>0.589304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.867644</td>\n",
       "      <td>0.845426</td>\n",
       "      <td>0.744845</td>\n",
       "      <td>0.470023</td>\n",
       "      <td>0.576326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.867541</td>\n",
       "      <td>0.845340</td>\n",
       "      <td>0.745807</td>\n",
       "      <td>0.468221</td>\n",
       "      <td>0.575255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.867534</td>\n",
       "      <td>0.845340</td>\n",
       "      <td>0.746025</td>\n",
       "      <td>0.467948</td>\n",
       "      <td>0.575111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.867533</td>\n",
       "      <td>0.845365</td>\n",
       "      <td>0.746068</td>\n",
       "      <td>0.468058</td>\n",
       "      <td>0.575207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.867532</td>\n",
       "      <td>0.845401</td>\n",
       "      <td>0.746352</td>\n",
       "      <td>0.467948</td>\n",
       "      <td>0.575206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.866660</td>\n",
       "      <td>0.843887</td>\n",
       "      <td>0.755153</td>\n",
       "      <td>0.447145</td>\n",
       "      <td>0.561655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.866657</td>\n",
       "      <td>0.843826</td>\n",
       "      <td>0.754992</td>\n",
       "      <td>0.446926</td>\n",
       "      <td>0.561440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.866417</td>\n",
       "      <td>0.844534</td>\n",
       "      <td>0.718350</td>\n",
       "      <td>0.502403</td>\n",
       "      <td>0.591036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.862286</td>\n",
       "      <td>0.827495</td>\n",
       "      <td>0.822476</td>\n",
       "      <td>0.291854</td>\n",
       "      <td>0.430795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.862286</td>\n",
       "      <td>0.827507</td>\n",
       "      <td>0.822710</td>\n",
       "      <td>0.291799</td>\n",
       "      <td>0.430765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.861686</td>\n",
       "      <td>0.855014</td>\n",
       "      <td>0.747211</td>\n",
       "      <td>0.531888</td>\n",
       "      <td>0.621337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.860830</td>\n",
       "      <td>0.781336</td>\n",
       "      <td>0.860190</td>\n",
       "      <td>0.026865</td>\n",
       "      <td>0.052101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.860302</td>\n",
       "      <td>0.777586</td>\n",
       "      <td>0.843956</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>0.014076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.860247</td>\n",
       "      <td>0.843581</td>\n",
       "      <td>0.718654</td>\n",
       "      <td>0.494649</td>\n",
       "      <td>0.585839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.860208</td>\n",
       "      <td>0.842274</td>\n",
       "      <td>0.720707</td>\n",
       "      <td>0.482474</td>\n",
       "      <td>0.577642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.859857</td>\n",
       "      <td>0.776414</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.859856</td>\n",
       "      <td>0.776414</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.858361</td>\n",
       "      <td>0.832454</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.568794</td>\n",
       "      <td>0.601358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857216</td>\n",
       "      <td>0.841725</td>\n",
       "      <td>0.716943</td>\n",
       "      <td>0.483346</td>\n",
       "      <td>0.577357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.855328</td>\n",
       "      <td>0.840564</td>\n",
       "      <td>0.704391</td>\n",
       "      <td>0.495522</td>\n",
       "      <td>0.581679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.845179</td>\n",
       "      <td>0.825308</td>\n",
       "      <td>0.606056</td>\n",
       "      <td>0.626349</td>\n",
       "      <td>0.615421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.844804</td>\n",
       "      <td>0.829339</td>\n",
       "      <td>0.640952</td>\n",
       "      <td>0.543191</td>\n",
       "      <td>0.587337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.841677</td>\n",
       "      <td>0.830512</td>\n",
       "      <td>0.657353</td>\n",
       "      <td>0.506225</td>\n",
       "      <td>0.571906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.758843</td>\n",
       "      <td>0.726005</td>\n",
       "      <td>0.424926</td>\n",
       "      <td>0.620237</td>\n",
       "      <td>0.503714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.647964</td>\n",
       "      <td>0.679358</td>\n",
       "      <td>0.341724</td>\n",
       "      <td>0.457737</td>\n",
       "      <td>0.390822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.635094</td>\n",
       "      <td>0.628814</td>\n",
       "      <td>0.312690</td>\n",
       "      <td>0.538991</td>\n",
       "      <td>0.395392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.630455</td>\n",
       "      <td>0.601710</td>\n",
       "      <td>0.314533</td>\n",
       "      <td>0.595824</td>\n",
       "      <td>0.409539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630410</td>\n",
       "      <td>0.654330</td>\n",
       "      <td>0.318381</td>\n",
       "      <td>0.479307</td>\n",
       "      <td>0.382440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624316</td>\n",
       "      <td>0.678319</td>\n",
       "      <td>0.332106</td>\n",
       "      <td>0.432620</td>\n",
       "      <td>0.375714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619222</td>\n",
       "      <td>0.658483</td>\n",
       "      <td>0.316875</td>\n",
       "      <td>0.455170</td>\n",
       "      <td>0.373579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.604844</td>\n",
       "      <td>0.574460</td>\n",
       "      <td>0.287278</td>\n",
       "      <td>0.574911</td>\n",
       "      <td>0.381699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601660</td>\n",
       "      <td>0.625858</td>\n",
       "      <td>0.295249</td>\n",
       "      <td>0.481814</td>\n",
       "      <td>0.365847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601660</td>\n",
       "      <td>0.625858</td>\n",
       "      <td>0.295249</td>\n",
       "      <td>0.481814</td>\n",
       "      <td>0.365847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601660</td>\n",
       "      <td>0.625858</td>\n",
       "      <td>0.295249</td>\n",
       "      <td>0.481814</td>\n",
       "      <td>0.365847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.593796</td>\n",
       "      <td>0.629156</td>\n",
       "      <td>0.286430</td>\n",
       "      <td>0.442668</td>\n",
       "      <td>0.347531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.586334</td>\n",
       "      <td>0.580225</td>\n",
       "      <td>0.284437</td>\n",
       "      <td>0.525610</td>\n",
       "      <td>0.367375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564450</td>\n",
       "      <td>0.599487</td>\n",
       "      <td>0.268281</td>\n",
       "      <td>0.453367</td>\n",
       "      <td>0.336464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559805</td>\n",
       "      <td>0.571210</td>\n",
       "      <td>0.254728</td>\n",
       "      <td>0.467618</td>\n",
       "      <td>0.328230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.554930</td>\n",
       "      <td>0.552254</td>\n",
       "      <td>0.253637</td>\n",
       "      <td>0.511738</td>\n",
       "      <td>0.338434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.536880</td>\n",
       "      <td>0.571785</td>\n",
       "      <td>0.260122</td>\n",
       "      <td>0.429227</td>\n",
       "      <td>0.322046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.535500</td>\n",
       "      <td>0.562966</td>\n",
       "      <td>0.248794</td>\n",
       "      <td>0.460800</td>\n",
       "      <td>0.322952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529880</td>\n",
       "      <td>0.630512</td>\n",
       "      <td>0.254996</td>\n",
       "      <td>0.342360</td>\n",
       "      <td>0.291924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.515360</td>\n",
       "      <td>0.516441</td>\n",
       "      <td>0.236882</td>\n",
       "      <td>0.496612</td>\n",
       "      <td>0.319731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.488757</td>\n",
       "      <td>0.589325</td>\n",
       "      <td>0.225475</td>\n",
       "      <td>0.338100</td>\n",
       "      <td>0.268828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.470859</td>\n",
       "      <td>0.578112</td>\n",
       "      <td>0.221688</td>\n",
       "      <td>0.322872</td>\n",
       "      <td>0.262090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_degree param_coef0 param_gamma  mean_test_roc_auc  \\\n",
       "0        1            3           1        0.01           0.880459   \n",
       "1        1            2           1        0.01           0.876455   \n",
       "2        1            3           1       0.001           0.875499   \n",
       "3     0.01            3           1        0.01           0.875315   \n",
       "4     0.01            2           1           1           0.872609   \n",
       "5     0.01            2        1000        0.01           0.871613   \n",
       "6        1            2           1       0.001           0.871585   \n",
       "7     0.01            2           1        0.01           0.870375   \n",
       "8        1            2        1000       0.001           0.868428   \n",
       "9     0.01            2        1000       0.001           0.867644   \n",
       "10       1            1        1000        0.01           0.867541   \n",
       "11       1            1           1        0.01           0.867534   \n",
       "12    0.01            1           1           1           0.867533   \n",
       "13    0.01            1        1000           1           0.867532   \n",
       "14       1            1        1000       0.001           0.866660   \n",
       "15       1            1           1       0.001           0.866657   \n",
       "16    1000            2        1000       0.001           0.866417   \n",
       "17    0.01            1        1000        0.01           0.862286   \n",
       "18    0.01            1           1        0.01           0.862286   \n",
       "19    1000            2           1       0.001           0.861686   \n",
       "20    0.01            3           1       0.001           0.860830   \n",
       "21    0.01            2           1       0.001           0.860302   \n",
       "22    1000            1           1       0.001           0.860247   \n",
       "23       1            1        1000           1           0.860208   \n",
       "24    0.01            1        1000       0.001           0.859857   \n",
       "25    0.01            1           1       0.001           0.859856   \n",
       "26    1000            1        1000       0.001           0.858361   \n",
       "27       1            1           1           1           0.857216   \n",
       "28    0.01            3        1000       0.001           0.855328   \n",
       "29    1000            3           1       0.001           0.845179   \n",
       "30    1000            3        1000       0.001           0.844804   \n",
       "31       1            3        1000       0.001           0.841677   \n",
       "32    1000            1        1000        0.01           0.758843   \n",
       "33    1000            3           1        0.01           0.647964   \n",
       "34    1000            1           1           1           0.635094   \n",
       "35       1            3        1000        0.01           0.630455   \n",
       "36    1000            3           1           1           0.630410   \n",
       "37    0.01            3           1           1           0.624316   \n",
       "38       1            3           1           1           0.619222   \n",
       "39    0.01            3        1000        0.01           0.604844   \n",
       "40       1            3        1000           1           0.601660   \n",
       "41    0.01            3        1000           1           0.601660   \n",
       "42    1000            3        1000           1           0.601660   \n",
       "43    0.01            2        1000           1           0.593796   \n",
       "44    1000            2        1000        0.01           0.586334   \n",
       "45       1            2        1000           1           0.564450   \n",
       "46    1000            2        1000           1           0.559805   \n",
       "47       1            2        1000        0.01           0.554930   \n",
       "48    1000            1           1        0.01           0.536880   \n",
       "49    1000            1        1000           1           0.535500   \n",
       "50       1            2           1           1           0.529880   \n",
       "51    1000            3        1000        0.01           0.515360   \n",
       "52    1000            2           1           1           0.488757   \n",
       "53    1000            2           1        0.01           0.470859   \n",
       "\n",
       "    mean_test_accuracy  mean_test_precision  mean_test_recall  mean_test_f1  \n",
       "0             0.858544             0.790836          0.499836      0.612527  \n",
       "1             0.856150             0.787229          0.489134      0.603370  \n",
       "2             0.849774             0.772615          0.465491      0.580922  \n",
       "3             0.844595             0.805392          0.402588      0.536818  \n",
       "4             0.857347             0.779234          0.505515      0.613215  \n",
       "5             0.848174             0.756023          0.474391      0.582960  \n",
       "6             0.847343             0.764178          0.459430      0.573807  \n",
       "7             0.839538             0.804965          0.373103      0.509859  \n",
       "8             0.847014             0.737581          0.490718      0.589304  \n",
       "9             0.845426             0.744845          0.470023      0.576326  \n",
       "10            0.845340             0.745807          0.468221      0.575255  \n",
       "11            0.845340             0.746025          0.467948      0.575111  \n",
       "12            0.845365             0.746068          0.468058      0.575207  \n",
       "13            0.845401             0.746352          0.467948      0.575206  \n",
       "14            0.843887             0.755153          0.447145      0.561655  \n",
       "15            0.843826             0.754992          0.446926      0.561440  \n",
       "16            0.844534             0.718350          0.502403      0.591036  \n",
       "17            0.827495             0.822476          0.291854      0.430795  \n",
       "18            0.827507             0.822710          0.291799      0.430765  \n",
       "19            0.855014             0.747211          0.531888      0.621337  \n",
       "20            0.781336             0.860190          0.026865      0.052101  \n",
       "21            0.777586             0.843956          0.007098      0.014076  \n",
       "22            0.843581             0.718654          0.494649      0.585839  \n",
       "23            0.842274             0.720707          0.482474      0.577642  \n",
       "24            0.776414             0.933333          0.000546      0.001091  \n",
       "25            0.776414             0.933333          0.000546      0.001091  \n",
       "26            0.832454             0.655555          0.568794      0.601358  \n",
       "27            0.841725             0.716943          0.483346      0.577357  \n",
       "28            0.840564             0.704391          0.495522      0.581679  \n",
       "29            0.825308             0.606056          0.626349      0.615421  \n",
       "30            0.829339             0.640952          0.543191      0.587337  \n",
       "31            0.830512             0.657353          0.506225      0.571906  \n",
       "32            0.726005             0.424926          0.620237      0.503714  \n",
       "33            0.679358             0.341724          0.457737      0.390822  \n",
       "34            0.628814             0.312690          0.538991      0.395392  \n",
       "35            0.601710             0.314533          0.595824      0.409539  \n",
       "36            0.654330             0.318381          0.479307      0.382440  \n",
       "37            0.678319             0.332106          0.432620      0.375714  \n",
       "38            0.658483             0.316875          0.455170      0.373579  \n",
       "39            0.574460             0.287278          0.574911      0.381699  \n",
       "40            0.625858             0.295249          0.481814      0.365847  \n",
       "41            0.625858             0.295249          0.481814      0.365847  \n",
       "42            0.625858             0.295249          0.481814      0.365847  \n",
       "43            0.629156             0.286430          0.442668      0.347531  \n",
       "44            0.580225             0.284437          0.525610      0.367375  \n",
       "45            0.599487             0.268281          0.453367      0.336464  \n",
       "46            0.571210             0.254728          0.467618      0.328230  \n",
       "47            0.552254             0.253637          0.511738      0.338434  \n",
       "48            0.571785             0.260122          0.429227      0.322046  \n",
       "49            0.562966             0.248794          0.460800      0.322952  \n",
       "50            0.630512             0.254996          0.342360      0.291924  \n",
       "51            0.516441             0.236882          0.496612      0.319731  \n",
       "52            0.589325             0.225475          0.338100      0.268828  \n",
       "53            0.578112             0.221688          0.322872      0.262090  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_table(grid, [\"C\", \"degree\", \"coef0\", \"gamma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0a9855-727a-405e-ad23-b2d2218d508a",
   "metadata": {},
   "source": [
    "Podemos ver que para la gran mayoría de las combinaciones de parámetros, el modelo no convergió en las 100000 iteraciones (el error nos sugiere estandarizar los datos, pero ya se hizo).\n",
    "\n",
    "El mejor modelo resultó ser el de un polinomio de grado 3, con C = 1, coef0 = 1 y gamma = 0.01. Los primeros de la lista son todos de grado 3, lo cual tiene sentido al estar menos sesgados. Como el grid search utiliza cross validation, confiamos en que no overfittearon.\n",
    "\n",
    "Vamos a entrenar un modelo con esos parámetros y probarlo con el set de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "389db321-934a-4b6c-8750-d04ff031e44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.882424</td>\n",
       "      <td>0.857045</td>\n",
       "      <td>0.793746</td>\n",
       "      <td>0.491301</td>\n",
       "      <td>0.606932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUC-ROC  Accuracy  Precision    Recall  F1 Score\n",
       "0  0.882424  0.857045   0.793746  0.491301  0.606932"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps.append(['svc', SVC(kernel = 'poly', random_state = 123, max_iter=100000,\n",
    "                             C = 1, degree = 3, coef0 = 1, gamma = 0.01)])\n",
    "\n",
    "pipe.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "metrics_table(pipe, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b877e-3245-4ff5-ba84-3eee3a9f1bb1",
   "metadata": {},
   "source": [
    "Con los parámetros encontrados, el modelo dio un accuracy de alrededor de 85,7% en promedio y área bajo la curva ROC de 0.882.\n",
    "\n",
    "El recall es bastante malo, lo que es de esperar siendo que el dataset tiene mucho más negativos que positivos. Tiende a predecir por la negativa, dando como resultado muchos falsos negativos y en consecuencia el bajo recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97383ca-e5cd-4a99-b38a-8db27037af54",
   "metadata": {},
   "source": [
    "## SVM Radial (RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff61607-5db9-472b-a6bc-3f437ff00c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_dataset()\n",
    "\n",
    "df_features = pd.read_csv(\"datasets/df_features.csv\", low_memory = False, index_col = \"id\")\n",
    "df_target = pd.read_csv(\"datasets/df_target.csv\", low_memory = False, index_col = \"id\")\n",
    "\n",
    "common(df_features, df_target)\n",
    "viento_trigonometrico(df_features)\n",
    "# El barrio tiene 49 valores distintos. Para no tener que hacer one hoy con 48 columnas nuevas, uso hashing trick\n",
    "df_features = hashing_trick(df_features, 24, \"barrio\")\n",
    "pipe2 = iterative_imputer()\n",
    "pipe2 = standarizer(pipe2)\n",
    "\n",
    "# Son los mismos sets, tienen el mismo random state\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_features, df_target, test_size = 0.20, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "103f11f0-94cd-4af7-b8bf-751b7ff8200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La grid tarda muchísimo en terminar, si se desea se puede cargar de archivo y saltear el próximo bloque\n",
    "# de código, descomentando la siguiente línea. También se pueden saltear los próximos 3 bloques de código si\n",
    "# solo se desea ver el modelo final con los parámetros encontrados.\n",
    "# grid2 = load('SVM/radial_grid.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2e6efe5-eb91-4946-8370-72dfb32f974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/delu/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8791220991523808"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_grid = pipe2.fit_transform(X_train)\n",
    "\n",
    "grid2 = GridSearchCV(SVC(kernel = 'rbf', random_state = 123, max_iter=100000),\n",
    "                    param_grid = {\n",
    "                        \"C\": [0.01, 1, 1000],\n",
    "                        \"gamma\": [0.001, 0.01, 1]\n",
    "                    },\n",
    "                    verbose = 1, n_jobs = -1, cv = 3, scoring = SCORINGS, refit = METRIC)\n",
    "\n",
    "grid2.fit(X_grid, Y_train.values.ravel())\n",
    "\n",
    "grid2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "297eaafe-68c9-4952-a070-377dfe51d420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM/radial_grid.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(grid2, 'SVM/radial_grid.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9edcf57a-cfd4-498b-834b-7da5c158ddb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.879122</td>\n",
       "      <td>0.857762</td>\n",
       "      <td>0.788735</td>\n",
       "      <td>0.497379</td>\n",
       "      <td>0.610049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.873783</td>\n",
       "      <td>0.848638</td>\n",
       "      <td>0.769968</td>\n",
       "      <td>0.461232</td>\n",
       "      <td>0.576850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.867683</td>\n",
       "      <td>0.857017</td>\n",
       "      <td>0.743791</td>\n",
       "      <td>0.551162</td>\n",
       "      <td>0.632968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.866850</td>\n",
       "      <td>0.826860</td>\n",
       "      <td>0.838492</td>\n",
       "      <td>0.279950</td>\n",
       "      <td>0.419734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.860568</td>\n",
       "      <td>0.777000</td>\n",
       "      <td>0.834213</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.007932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.780974</td>\n",
       "      <td>0.776548</td>\n",
       "      <td>0.646962</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.004787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.780150</td>\n",
       "      <td>0.776304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.779413</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>0.014631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.690681</td>\n",
       "      <td>0.720533</td>\n",
       "      <td>0.389446</td>\n",
       "      <td>0.430487</td>\n",
       "      <td>0.408606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_gamma  mean_test_roc_auc  mean_test_accuracy  \\\n",
       "0       1        0.01           0.879122            0.857762   \n",
       "1       1       0.001           0.873783            0.848638   \n",
       "2    1000       0.001           0.867683            0.857017   \n",
       "3    0.01        0.01           0.866850            0.826860   \n",
       "4    0.01       0.001           0.860568            0.777000   \n",
       "5       1           1           0.780974            0.776548   \n",
       "6    0.01           1           0.780150            0.776304   \n",
       "7    1000           1           0.779413            0.776316   \n",
       "8    1000        0.01           0.690681            0.720533   \n",
       "\n",
       "   mean_test_precision  mean_test_recall  mean_test_f1  \n",
       "0             0.788735          0.497379      0.610049  \n",
       "1             0.769968          0.461232      0.576850  \n",
       "2             0.743791          0.551162      0.632968  \n",
       "3             0.838492          0.279950      0.419734  \n",
       "4             0.834213          0.003986      0.007932  \n",
       "5             0.646962          0.002403      0.004787  \n",
       "6             0.000000          0.000000      0.000000  \n",
       "7             0.500000          0.007426      0.014631  \n",
       "8             0.389446          0.430487      0.408606  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_table(grid2, [\"C\", \"gamma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04d625-9e4c-4c32-9570-d59787172d22",
   "metadata": {},
   "source": [
    "Nuevamente, la mayoría de los modelos con cada combinación de los parámetros no logró converger antes de las iteraciones dadas. Casi todos los modelos dieron 77% de accuracy, lo cual es muy malo ya que probablemente hayan fiteado a decir siempre que \"no\" al estar desbalanceada la variable target. El que dio recall y precision en 0 overfitteo por completo (0 true positives, entonces 0 de recall y precision).\n",
    "\n",
    "Los primeros si dieron valores más aceptables, siendo el de mejor el que usa C=1 y gamma=0.01. Vamos a utilizar esos valores para entrenar un modelo con todo el set de entrenamietno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489c4b3a-1fd7-49e8-ac76-82de688fe5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880191</td>\n",
       "      <td>0.856263</td>\n",
       "      <td>0.793409</td>\n",
       "      <td>0.486951</td>\n",
       "      <td>0.603504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUC-ROC  Accuracy  Precision    Recall  F1 Score\n",
       "0  0.880191  0.856263   0.793409  0.486951  0.603504"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.steps.append(['svc', SVC(kernel = 'rbf', random_state = 123, max_iter=100000, C = 1, gamma = 0.01)])\n",
    "\n",
    "pipe2.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "metrics_table(pipe2, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ff338-87ce-48ae-82b3-148820b402cf",
   "metadata": {},
   "source": [
    "En este caso el modelo radial dio un 0.880 de área bajo curva ROC y accuracy del 85,6%, muy levemente por debajo del polinómico. El  recall sigue siendo malo, tiene muchos falsos negativos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
