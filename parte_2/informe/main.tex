%
% Carátula oficial de 75.02 Algoritmos y Programación I, cátedra Cardozo.
%
% Basado en el template realizado por Diego Essaya, disponible en
%                                                         http://lug.fi.uba.ar
% Modificado por Michel Peterson.
% Modificado por Sebastián Santisi.

%
% Acá se define el tamaño de letra principal:
%
\documentclass[12pt]{article}

%
% Título y autor(es):
%
\title{Trabajo Práctico N\b o X}
\author{Apellido1\\Apellido2}

%------------------------- Carga de paquetes ---------------------------
%
% Si no necesitás algún paquete, comentalo.
%

%
% Definición del tamaño de página y los márgenes:
%
\usepackage[margin=1in]{geometry}

%
% Vamos a escribir en castellano:
%
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}


\usepackage{array}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{ltxtable}

\usepackage{changepage}

%
% Si preferís el tipo de letra Helvetica (Arial), descomentá las siguientes
% dos lineas (las fórmulas seguirán estando en Times):
%
%\usepackage{helvet}
%\renewcommand\familydefault{\sfdefault}

%
% El paquete amsmath agrega algunas funcionalidades extra a las fórmulas. 
% Además defino la numeración de las tablas y figuras al estilo "Figura 2.3", 
% en lugar de "Figura 7". (Por lo tanto, aunque no uses fórmulas, si querés
% este tipo de numeración dejá el paquete amsmath descomentado).
%
\usepackage{amsmath}
\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}

%
% Para tener cabecera y pie de página con un estilo personalizado:
%
\usepackage{fancyhdr}

%
% Para poner el texto "Figura X" en negrita:
% (Si no tenés el paquete 'caption2', probá con 'caption').
%
\usepackage[hang,bf]{caption}

%
% Para poder usar subfiguras: (al estilo Figura 2.3(b) )
%
%\usepackage{subfigure}

%
% Para poder agregar notas al pie en tablas:
%
%\usepackage{threeparttable}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

%------------------------------ graphicx ----------------------------------
%
% Para incluir imágenes, el siguiente código carga el paquete graphicx 
% según se esté generando un archivo dvi o un pdf (con pdflatex). 

% Para generar dvi, descomentá la linea siguiente:
%\usepackage[dvips]{graphicx}

% Para generar pdf, descomentá las dos lineas seguientes:
\usepackage[pdftex]{graphicx}
\pdfcompresslevel=9

%
% Todas las imágenes están en el directorio tp-img:
%
\newcommand{\imgdir}{includes}
\graphicspath{{\imgdir/}}
%
%------------------------------ graphicx ----------------------------------

% Necesitas este paquete si haces los diagrámas de flujo en el prográma Dia 
%\usepackage{tikz}


%------------------------- Inicio del documento ---------------------------

\begin{document}
	
	%
	% Hago que en la cabecera de página se muestre a la derecha la sección,
	% y en el pie, en número de página a la derecha:
	%
	\pagestyle{fancy}
	\renewcommand{\sectionmark}[1]{\markboth{}{\thesection\ \ #1}}
	\lhead{}
	\chead{}
	\rhead{\rightmark}
	\lfoot{}
	\cfoot{}
	\rfoot{\thepage}
	
	%
	% Carátula:
	%
	\begin{titlepage}
		
		\thispagestyle{empty}
		
		\begin{center}
			\includegraphics[scale=0.3]{fiuba}\\
			\large{\textsc{Universidad de Buenos Aires}}\\
			\large{\textsc{Facultad De Ingeniería}}\\
			\small{Año 2021 - 2\textsuperscript{do} Cuatrimestre}
		\end{center}
		
		\vfill
		
		\begin{center}
			\Large{\underline{\textsc{Organización de Datos (75.06)}}}
		\end{center}
		
		\vfill
		
		\begin{tabbing}
			\hspace{2cm}\=\+TRABAJO PRÁCTICO Nº2\\
			TEMA: \\
			FECHA DE ENTREGA: 8/12/2021\\% \today\\
			\\
			INTEGRANTES:\hspace{-1cm}\=\+\hspace{1cm}\=\hspace{6cm}\=\\
			DE LUCA ANDREA, Felipe	\>\>- \#88888\\
			FOPPIANO, Elián	\>\>- \#88888\\
		\end{tabbing}
		
		\vfill
		
		\hrule
		\vspace{0.2cm}
		
		\noindent\small{75.06 - Organización de Datos}
		
	\end{titlepage}
	
	%
	% Hago que las páginas se comiencen a contar a partir de aquí:
	%
	\setcounter{page}{1}
	
	%
	% Pongo el índice en una página aparte:
	%
	\tableofcontents
	\newpage
	
	%
	% Inicio del TP:
	%
	\newgeometry{margin=0.2in}
	
	\section{Preprocesamientos}
	
	\begingroup
	\fontsize{11pt}{12pt}\selectfont
	
	\LTXtable{\textwidth}{plantilla_preprocesamientos.tex}
	
	\endgroup

	\pagebreak

	\section{Modelos}

	\begingroup
	\fontsize{11pt}{12pt}\selectfont
	
	\LTXtable{\textwidth}{plantilla_metricas.tex}
	
	\endgroup
	
	
	\restoregeometry
	
	\pagebreak

	\section{Conclusión}
	De todos los modelos entrenados, los dos que resultaron ser mejores 
	fueron la red neuronal y el ensamble en cascada. En ambos casos su
	AUC-ROC fue de 0.895, lo cual es bastante aceptable. Si tuvieramos que
	elegir uno, nos decantaríamos por la red neuronal, ya que es el modelo
	más sencillo de los dos: el cascading ya de por sí tiene como uno de los
	modelos que utiliza a la misma red.

	La baseline que hicimos a partir del análisis de los datos tenía un
	accuracy de alrededor de $83\%$. Podemos ver que esta métrica fue
	ampliamente superada por casi todos los modelos (exceptuando el
	perceptrón y Naive Bayes), por lo que los resultados fueron bastante
	positivos.

	Algo a notar es que todos los modelos tienen un Recall bastante bajo.
	El Recall es una métrica que responde a la pregunta: de las instancias
	positivas, ¿qué porcentaje fueron clasificadas correctamente?. Debido
	a que el dataset utilizado estaba bastante desbalanceado, todos los modelos
	tendieron a aprender a responder por la negativa. Esto provocó que haya
	una gran cantidad de falsos negativos, lo que es la causa de que esta métrica
	haya dado tan baja.

	Si tuvieramos que elegir el modelo con la menor cantidad de falsos positivos,
	eligiríamos el que tiene el Precision más alto, que responde a la pregunta:
	de los detectadaos como positivos, ¿qué porcentaje realmente lo eran?. Entonces,
	a Precision más alto, menor cantidad de falsos positivos. En este caso, el
	modelo con Precision más alto resultó ser el \textit{AdaBoostClassifier}. Podemos
	notar que esa ganancia no fue gratuita: perdió mucho en Recall.

	Si necesitaramos una lista de los potenciales días que vayan a llover, es decir,
	minimizar los falsos negativos, volveríamos al problema del Recall. El modelo
	con mejor Recall en este caso es Naive Bayes. Nuevamente, pierde mucho en otras
	métricas: es el segundo peor modelo en nuestra lista ordenada por AUC-ROC. De
	todas formas, los modelos encontrados tienen todos un Recall exageradamente bajo, y
	si realmente necesitaramos tener pocos falsos negativos, probablemente intentaramos
	con modelos nuevos o incluso pensamos que sería mejor un modelo que responda siempre
	que 'si' antes que los que pudimos entrenar.

	Podemos también considerar que a la hora de entrenar los modelos, se optimizó para 
	maximizar la métrica de AUC-ROC. Si nos encontraramos en los 2 casos hipotéticos
	descritos en los párrafos anteriores, probablemente hubieramos elegido otros
	hiperpárametros en los modelos a entrenar. Por ejemplo, en el notebook del 
	árbol de decisión, si elegíamos el parámetro de \textit{class\_weight} = 
	``\textit{balanced}'', daba bastante mejor Recall que en el que terminó quedando en la
	 tabla anterior.

	
\end{document}

