%
% Carátula oficial de 75.02 Algoritmos y Programación I, cátedra Cardozo.
%
% Basado en el template realizado por Diego Essaya, disponible en
%                                                         http://lug.fi.uba.ar
% Modificado por Michel Peterson.
% Modificado por Sebastián Santisi.

%
% Acá se define el tamaño de letra principal:
%
\documentclass[12pt]{article}

%
% Título y autor(es):
%
\title{Trabajo Práctico N\b o X}
\author{Apellido1\\Apellido2}

%------------------------- Carga de paquetes ---------------------------
%
% Si no necesitás algún paquete, comentalo.
%

%
% Definición del tamaño de página y los márgenes:
%
\usepackage[margin=1in]{geometry}

%
% Vamos a escribir en castellano:
%
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}


\usepackage{array}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{ltxtable}

\usepackage{changepage}

%
% Si preferís el tipo de letra Helvetica (Arial), descomentá las siguientes
% dos lineas (las fórmulas seguirán estando en Times):
%
%\usepackage{helvet}
%\renewcommand\familydefault{\sfdefault}

%
% El paquete amsmath agrega algunas funcionalidades extra a las fórmulas. 
% Además defino la numeración de las tablas y figuras al estilo "Figura 2.3", 
% en lugar de "Figura 7". (Por lo tanto, aunque no uses fórmulas, si querés
% este tipo de numeración dejá el paquete amsmath descomentado).
%
\usepackage{amsmath}
\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}

%
% Para tener cabecera y pie de página con un estilo personalizado:
%
\usepackage{fancyhdr}

%
% Para poner el texto "Figura X" en negrita:
% (Si no tenés el paquete 'caption2', probá con 'caption').
%
\usepackage[hang,bf]{caption}

%
% Para poder usar subfiguras: (al estilo Figura 2.3(b) )
%
%\usepackage{subfigure}

%
% Para poder agregar notas al pie en tablas:
%
%\usepackage{threeparttable}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

%------------------------------ graphicx ----------------------------------
%
% Para incluir imágenes, el siguiente código carga el paquete graphicx 
% según se esté generando un archivo dvi o un pdf (con pdflatex). 

% Para generar dvi, descomentá la linea siguiente:
%\usepackage[dvips]{graphicx}

% Para generar pdf, descomentá las dos lineas seguientes:
\usepackage[pdftex]{graphicx}
\pdfcompresslevel=9

%
% Todas las imágenes están en el directorio tp-img:
%
\newcommand{\imgdir}{includes}
\graphicspath{{\imgdir/}}
%
%------------------------------ graphicx ----------------------------------

% Necesitas este paquete si haces los diagrámas de flujo en el prográma Dia 
%\usepackage{tikz}


%------------------------- Inicio del documento ---------------------------

\begin{document}
	
	%
	% Hago que en la cabecera de página se muestre a la derecha la sección,
	% y en el pie, en número de página a la derecha:
	%
	\pagestyle{fancy}
	\renewcommand{\sectionmark}[1]{\markboth{}{\thesection\ \ #1}}
	\lhead{}
	\chead{}
	\rhead{\rightmark}
	\lfoot{}
	\cfoot{}
	\rfoot{\thepage}
	
	%
	% Carátula:
	%
	\begin{titlepage}
		
		\thispagestyle{empty}
		
		\begin{center}
			\includegraphics[scale=0.3]{fiuba}\\
			\large{\textsc{Universidad de Buenos Aires}}\\
			\large{\textsc{Facultad De Ingeniería}}\\
			\small{Año 2021 - 2\textsuperscript{do} Cuatrimestre}
		\end{center}
		
		\vfill
		
		\begin{center}
			\Large{\underline{\textsc{Organización de Datos (75.06)}}}
		\end{center}
		
		\vfill
		
		\begin{tabbing}
			\hspace{2cm}\=\+TRABAJO PRÁCTICO Nº2\\
			TEMA: Lluvia de hamburguesas \\
			FECHA DE ENTREGA: 8/12/2021\\% \today\\
			\\
			INTEGRANTES:\hspace{-1cm}\=\+\hspace{1cm}\=\hspace{6cm}\=\\
			DE LUCA ANDREA, Felipe	\>\>- \#105646\\
			FOPPIANO, Elián	\>\>- \#105836\\
		\end{tabbing}
		
		\vfill
		
		\hrule
		\vspace{0.2cm}
		
		\noindent\small{75.06 - Organización de Datos}
		
	\end{titlepage}
	
	%
	% Hago que las páginas se comiencen a contar a partir de aquí:
	%
	\setcounter{page}{1}
	
	%
	% Pongo el índice en una página aparte:
	%
	\tableofcontents
	\newpage
	
	%
	% Inicio del TP:
	%
	\newgeometry{margin=0.2in}
	
	\section{Preprocesamientos}
	
	\begingroup
	\fontsize{11pt}{12pt}\selectfont
	
	\LTXtable{\textwidth}{plantilla_preprocesamientos.tex}
	
	\endgroup

	\pagebreak

	\section{Modelos}
	Todas las métricas presentadas fueron evaluadas respecto al set de
	test-holdout, que no fue utilizado durante el entrenamiento ni
	para la selección del preprocesamiento e hiperparámetros de cada modelo.

	\begingroup
	\fontsize{11pt}{12pt}\selectfont
	
	\LTXtable{\textwidth}{plantilla_metricas.tex}
	
	\endgroup
	
	
	\restoregeometry
	
	\pagebreak

	\section{Conclusión}
	De todos los modelos entrenados, el que mejor resultó de acuerdo a
	el área bajo la curva ROC fue la red neuronal, que le dio un valor de
	de 0.896, lo cual es bastante aceptable. Los ensambles de Cascading
	y AdaBoost estuvieron bastante cerca, pero levemente por debajo.

	La baseline que hicimos a partir del análisis de los datos tenía un
	accuracy de alrededor de $83\%$. Podemos ver que esta métrica fue
	ampliamente superada por casi todos los modelos (exceptuando el
	perceptrón y Naive Bayes), por lo que los resultados fueron en general
	bastante positivos.

	Algo a notar es que todos los modelos tienen un Recall bastante bajo.
	El Recall es una métrica que responde a la pregunta: de las instancias
	positivas, ¿qué porcentaje fueron clasificadas correctamente?. Debido
	a que el dataset utilizado estaba bastante desbalanceado, todos los modelos
	tendieron a aprender a responder por la negativa. Esto provocó que haya
	una gran cantidad de falsos negativos, lo que es la causa de que esta métrica
	haya dado tan baja.

	Si tuvieramos que elegir el modelo con la menor cantidad de falsos positivos,
	eligiríamos el que tiene el Precision más alto, que responde a la pregunta:
	de los detectadaos como positivos, ¿qué porcentaje realmente lo eran?. Entonces,
	a Precision más alto, menor cantidad de falsos positivos. En este caso, el
	modelo con Precision más alto resultó ser el \textit{SVM}, con un valor de 
	0.796. Podemos ver que notar que esa ganancia no fue gratuita: perdió en Recall.

	Si necesitaramos una lista de los potenciales días que vayan a llover, es decir,
	minimizar los falsos negativos, volveríamos al problema del Recall. El modelo
	con mejor Recall en este caso es Naive Bayes. Nuevamente, pierde mucho en otras
	métricas: es el segundo peor modelo en nuestra lista ordenada por AUC-ROC. De
	todas formas, los modelos encontrados tienen todos un Recall exageradamente bajo, y
	si realmente necesitaramos tener pocos falsos negativos, probablemente intentaramos
	con modelos nuevos o incluso pensamos que sería mejor un modelo que responda siempre
	que 'si' antes que los que pudimos entrenar.

	Podemos también considerar que a la hora de entrenar los modelos, se optimizó para 
	maximizar la métrica de AUC-ROC. Si nos encontraramos en los 2 casos hipotéticos
	descritos en los párrafos anteriores, probablemente hubieramos elegido otros
	hiperpárametros en los modelos a entrenar. Por ejemplo, en el notebook del 
	árbol de decisión, si elegíamos el parámetro de \textit{class\_weight} = 
	``\textit{balanced}'', daba bastante mejor Recall que en el que terminó quedando en la
	tabla anterior. Para entrenar la red, podríamos haber frenado el progreso de las epochs
	con una métrica como F-score con $\beta = 2$, que prioriza el Recall dos veces más que
	la Precision.

	
\end{document}

